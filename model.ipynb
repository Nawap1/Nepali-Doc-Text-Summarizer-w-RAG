{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_face_token = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Programs\\anaconda3\\envs\\nepsum\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "summarizer = HuggingFaceHub(\n",
    "        repo_id=\"csebuetnlp/mT5_multilingual_XLSum\",\n",
    "        model_kwargs={\"temperature\":0, \"max_length\":84},\n",
    "        huggingfacehub_api_token = hugging_face_token,\n",
    "    )\n",
    "\n",
    "#GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#Preprocessing\n",
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_summarizer(path)->str:\n",
    "    '''\n",
    "    Takes file path of the document which needs to be summarized and returns the summarized text.\n",
    "    path: str - path of the document to be summarized.\n",
    "    returns: str - summarized text of the document.\n",
    "    '''\n",
    "  \n",
    "    if path.endswith('.txt'):\n",
    "        text = text_splitter.split_text(WHITESPACE_HANDLER(open(path).read()))\n",
    "        \n",
    "    elif path.endswith('.pdf'):\n",
    "        pdf_reader = PdfReader(path)\n",
    "        extracted_text = ''\n",
    "\n",
    "        for i in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[i]\n",
    "            extracted_text += page.extract_text()\n",
    "        extracted_text = WHITESPACE_HANDLER(extracted_text)\n",
    "        text = text_splitter.split_text(extracted_text)\n",
    "    return summarizer(f\"Summarize this: {text}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'दक्षिण एशियाली खेलकुदमा नेपाललाई तीन गोलले पराजित गरेपछि नेपाली फुटबल टोलीकी कप्तान एवम् सावित्राले अन्तर्राष्ट्रिय खेलमा गोल गरेर नयाँ कीर्तिमान बनाएकी छन् ।'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_summarizer('sample.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    "Now all the components are combined to create an api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Programs\\anaconda3\\envs\\nepsum\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import torch\n",
    "import re\n",
    "\n",
    "#Initializations\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    "    )\n",
    "\n",
    "summarizer = HuggingFaceHub(\n",
    "        repo_id=\"csebuetnlp/mT5_multilingual_XLSum\",\n",
    "        model_kwargs={\"temperature\":0, \"max_length\":84},\n",
    "        huggingfacehub_api_token = hugging_face_token,\n",
    "    )\n",
    "\n",
    "#GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#Preprocessing\n",
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "\n",
    "def doc_summarizer(path)->str:\n",
    "    '''\n",
    "    Takes file path of the document which needs to be summarized and returns the summarized text.\n",
    "    path: str - path of the document to be summarized.\n",
    "    returns: str - summarized text of the document.\n",
    "    '''\n",
    "  \n",
    "    if path.endswith('.txt'):\n",
    "        text = text_splitter.split_text(WHITESPACE_HANDLER(open(path).read()))\n",
    "        \n",
    "    elif path.endswith('.pdf'):\n",
    "        pdf_reader = PdfReader(path)\n",
    "        extracted_text = ''\n",
    "\n",
    "        for i in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[i]\n",
    "            extracted_text += page.extract_text()\n",
    "        extracted_text = WHITESPACE_HANDLER(extracted_text)\n",
    "        text = text_splitter.split_text(extracted_text)\n",
    "    return summarizer(f\"Summarize this: {text}!\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc_sum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
